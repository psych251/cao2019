---
title: "Untitled"
author: "Joseph"
date: "11/19/2020"
output: html_document
---

---
title: "Replication of People make the Same Bayesian Judgment They Criticize in Others by Cao, Kleiman-Weiner and Banaji (2019, Psychological Science)"
author: "Joseph Outa (joouta@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

I chose this paper because it's an experimental application of Bayes theorem, a ubiquitous framework in the social sciences. Replicating it will require me to internalize the theorem's basic intuition as well as its more complex manifestations. The experimental paradigm involves a qualitative and computational exploration of how beliefs are updated with evidence. This is a great opportunity to think about how Bayesian principles fit in with people's real world decision-making, an invaluable tool in a social scientist's arsenal. 

This paper explored participants' judgments about the likelihood of a hypothetical person being of a particular occupation based on idiosyncratic statistical heuristics. The replication target will be study 5, which will consist of three parts; the first part will query people's prior, posterior, and likelihood estimates of an air traffic control (ATC) communicator either being male or female; the second part will compute a model posterior for each participant and compare it with their actual posterior; and the third part will have the participants evaluate the moral character of a third party who makes a Bayesian judgment about the same scenario.

If the results of the original study hold, this study expects to find that participants make Bayesian judgments about the ATC scenario, with actual and model posteriors favoring the communicator being male rather than female. A second key finding will be that participants will judge a third party who makes the same Bayesian judgments as themselves as being unfair, unjust, inaccurate and unintelligent.The study is expected to be conducted on Amazon's task crowd-sourcing marketplace, Mechanical Turk. Some challenges expected include low quality of data due to bots or inattentive participants, and the possibility of participants looking up answers to the filler questions about unrelated statistical phenomena.

Link to the [repository](https://github.com/psych251/cao2019)  
Link to the [Qualtrics survey](https://stanforduniversity.qualtrics.com/jfe/form/SV_80xBOBxnipQ3R4x)
Link to the preregistration: 

## Methods

### Power Analysis

Using the G*Power software, the original effect size was calculated to be d = 0.48, and the planned sample size to achieve 80% power was calculated to be 36

### Planned Sample

Planned sample size = 36

### Materials and Procedure

The study will be conducted in October 2020. Participants will be recruited from Amazon Mturk and compensated $0.71 each. The study will proceed in four parts, the first three of which will correspond to a component of
Bayes’s rule.

"In the first part, each participant was randomly assigned to learn that either a man or a woman had communicated with air traffic control during a flight. Participants provided their priors, posteriors, and likelihoods for this scenario"


"Part 1: priors. Participants will be instructed to imagine a man and a woman who work at the same airline. One person is a pilot and the other person is not a pilot, but who is the pilot and who is not is unknown. Participants will estimate the percentage chance that each person is the pilot. Because there are two hypotheses—either the man or the woman is the pilot (and the other is the
not)—both estimates had to sum to 1. Thus, each participant will provide his or her subjective prior about each person’s profession (e.g., the man has a 75% chance of being the pilot; the woman has a 25% chance of being not the pilot).

Part 2: posteriors. After providing priors, each participant will be randomly assigned to learn one of the following two pieces of data: (a) The man communicated with air traffic control(b) the woman communicated with air traffic control. After learning this datum, participants will again estimated the percentage chance that each person is the pilot. Thus, each participant will provide his or her subjective posterior.

Part 3: likelihoods. Each participant will estimate two likelihoods: the likelihood of observing the datum given the hypothesis that the target they learned about is the pilot and the likelihood of observing the datum given the hypothesis that the target they learned about is not the pilot. For example, if a participant learned that the woman had communicated with air traffic control, that participant will estimate the percentage of female pilots who communicate with air traffic control and the percentage of female non-pilots who communicate with air traffic control. If a participant learned that the man had communicated with air traffic control, that participant will estimated the percentage of male pilots who communicate with air traffic control and the percentage of male non-pilots who communicate with air traffic control. Thus, each participant will provide his or her subjective likelihood estimates, which will be combined by forming a ratio. Each participant will be randomly assigned to estimate the corresponding likelihoods either before or after providing subjective priors and posteriors. Each participant’s priors and likelihoods will be entered into Bayes’s rule to compute a model posterior, which represents what the participant’s posterior should be from a statistical perspective. This model posterior will be compared with the posterior that the participant actually reported.

Next, participants will learn about person X, who stated the following after learning the same information as participants: “Even though the man and the woman both communicated with air traffic control (ATC), the man is more likely to be a doctor than the woman.” Participants then completed four Likert-type scales that assessed how (a) fair, (b) just, (c) accurate, and (d) intelligent person X’s statement was. Each scale ranged from 1 (e.g., extremely unfair) to 7 (e.g., extremely fair)."

### Analysis Plan

Participants will be excluded who provide priors of either 0% of 100% since these cannot be updated in accordance with Bayes rule. 

"Each participant’s priors and likelihoods will be entered into Bayes’s rule to compute a model posterior, which represents what the participant’s posterior should be from a statistical perspective. This model posterior will be compared with the posterior that the participant actually reported."

Key descriptive statistics such as means and standard errors for judgments among participants in each condition will be computed and some plotted. 


**Clarify key analysis of interest here** 

The key statistical test I will replicate will be the two-way ANOVA with linear model fit examining the effects of person X evaluations ([1] negative to [7] positive) and target gender (male or female) on posterior judgments. These findings were represented visually in figure 4. 
 

The analysis

### Differences from Original Study

The study is expected to be replicated with a much smaller sample than the original 353 due to budget concerns. A power analysis will be conducted to determine the ideal sample size under which an effect is expected to be observed. 
The procedure and analysis will be the same one used in study 5. A key difference is that the replication study will not ask participants to complete filler tasks consisting of unrelated statistical judgments on the second part of the study, as the authors did. This was done because it was determined that the results of the filler questions were inconsequential to the conclusions.


### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


# Data Preparation

Data preparation following the analysis plan.

## Data Wrangling

```{r setup, include=FALSE}
#### Load Relevant Libraries and Functions
library(tidyverse)
library(dplyr)
library(plyr)
library(knitr)
library(srvyr)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
caodata = read_csv("cao_final.csv")
colnames(caodata)

```
	
### Rename and Tidy columns

```{r}
data <- caodata %>% 
   rename(#man condition
          cond1.prior_manPilot.womanFlightAttendant = X1.prior_1,  #prior prob that man is pilot
          cond1.prior_womanPilot.manFlightAttendant = X1.prior_2, #prior prob that woman is pilot
          cond1.post_manPilot.womanFlightAttendant = X1.post_1, #posterior prob that man is pilot
          cond1.post_womanPilot.manFlightAttendant = X1.post_2, #posterior prob woman is pilot
          cond1.lk_percent.male.pilots.comm.ATC = X1.lk_1_1,  
          cond1.lk_percent.male.flightAttendants.comm.ATC = X1.lk_2_1,
          
          ##woman condition
          cond2.prior_manPilot.womanFlightAttendant = X2.prior_1, #prior prob that man is pilot
          cond2.prior_womanPilot.manFlightAttendant = X2.prior_2, #prior prob that woman is pilot
          cond2.post_manPilot.womanFlightAttendant = X2.post_1, #posterior prob that man is pilot
          cond2.post_womanPilot.manFlightAttendant = X2.post_2, #posterior prob woman is pilot
          cond2.lk_percent.female.pilots.comm.ATC = X2.lk_1_1,
          cond2.lk_percent.female.flightAttendants.comm.ATC = X2.lk_2_1
          ) 

# Filter out columns with answers to Trivial Questions
data <- select(data, !starts_with("Q"))

```


### Tidy rows and remove blanks

```{r}
#Removing irrelevant column titles
rowlength <- length(data$ResponseId) #check length of data frame = 
data <- data[3:rowlength,] #excludes row 1 and 2

#Removing Survey Preview rows aka Rows with Status 1 and unfinished rows
data <- filter(data, Status==0)
data <- filter(data, Finished==1) #Removing unfinished rows

## Remove empty/ blank responses in both conditions
data_noblank <- data %>%
  filter(!is.na(cond1.prior_manPilot.womanFlightAttendant) | !is.na(cond2.prior_manPilot.womanFlightAttendant))
data_noblank

# How many exclusions?
Blank_excl_total <- length(data$ResponseId) - length(data_noblank$ResponseId) 
Blank_excl_total # X exclusions

data <- data_noblank

```

### Arranging columns

```{r}
#first sort by condition
data_arr <- arrange(data, cond1.prior_manPilot.womanFlightAttendant)

#create condition column
datac <- data_arr %>%
  mutate(condition = ifelse(is.na(cond1.prior_manPilot.womanFlightAttendant), "2", "1")
         )
```

### Convert judgments from character to numeric

```{r}

## ========================================== ##
## Convert judgments from factor to numeric
colnames(datac)
str(datac)

#11 to 16 and 22 to 27

#cond1
datac[11:16] <- sapply(X = datac[11:16],
                     FUN = as.numeric)


#cond2
datac[23:28] <- sapply(X = datac[23:28],
                     FUN = as.numeric)

## ========================================== ##
## Convert attributions from factor to numeric
str(datac)
colnames(datac)
  
 ## cond 1 

datac[18:21] <- sapply(X = datac[18:21], 
                     FUN = as.numeric)

# cond2
datac[30:33] <- sapply(X = datac[30:33], 
                     FUN = as.numeric)

str(datac)
## ========================================== ##

```


### Sorting Prior attributions

```{r}
## Prior.Man.Pilot: prior probability that man is the Pilot
datac$Prior.Man.Pilot <- NA

datac$Prior.Man.Pilot[datac$condition == "1"] <- datac$cond1.prior_manPilot.womanFlightAttendant[datac$condition == "1"]
datac$Prior.Man.Pilot[datac$condition == "2"] <- datac$cond2.prior_manPilot.womanFlightAttendant[datac$condition == "2"]

## Prior.Woman.Pilot: prior probability that woman is the Pilot
datac$Prior.Woman.Pilot <- NA

datac$Prior.Woman.Pilot[datac$condition == "1"] <- datac$cond1.prior_womanPilot.manFlightAttendant[datac$condition == "1"]
datac$Prior.Woman.Pilot[datac$condition == "2"] <- datac$cond2.prior_womanPilot.manFlightAttendant[datac$condition == "2"]

#confirm that priors sum up to 100%
count(with(datac, Prior.Man.Pilot + Prior.Woman.Pilot)) # doesn't work
datac$Prior.Man.Pilot + datac$Prior.Woman.Pilot  # -->> works #sum is 100

#some notes:
datac <- transform(datac, Prior.Man.Pilot = as.numeric(Prior.Man.Pilot), 
                          Prior.Woman.Pilot = as.numeric(Prior.Woman.Pilot))


## Peak at distribution of priors overall
hist(datac$Prior.Man.Pilot)


##-----------------------------------##
datac$target <- NA
datac[grepl("^1$", datac$condition), "target"] <- "man"
datac[grepl("^2$", datac$condition), "target"] <- "woman"

datac$target <- factor(x = datac$target, 
                     levels = c("man", "woman"))

## Prior.Target.Pilot
datac$Prior.Target.Pilot <- ifelse(test = datac$target == "man", 
                                 yes = datac$Prior.Man.Pilot, 
                                 no = datac$Prior.Woman.Pilot)

select(datac, Prior.Target.Pilot)

## ================================================================== ##
## Able to update
summarise(datac, Prior.Target.Pilot=n()) #this works!

datac$able.to.update <- ifelse(test = datac$Prior.Target.Pilot == 1 | datac$Prior.Target.Pilot == 0, 
                             yes = "no", 
                             no = "yes")


count(datac$able.to.update)
  ## x participants can't update their priors


# repeat for posteriors:

## =================================================================== ##

## Posterior.Man.Pilot: posterior probability that man is the Pilot
datac$Posterior.Man.Pilot <- NA

datac$Posterior.Man.Pilot[datac$condition == "1"] <- datac$cond1.post_manPilot.womanFlightAttendant[datac$condition == "1"]
datac$Posterior.Man.Pilot[datac$condition == "2"] <- datac$cond2.post_manPilot.womanFlightAttendant[datac$condition == "2"]

## Posterior.Woman.Pilot: prior probability that woman is the Pilot
datac$Posterior.Woman.Pilot <- NA

datac$Posterior.Woman.Pilot[datac$condition == "1"] <- datac$cond1.post_womanPilot.manFlightAttendant[datac$condition == "1"]
datac$Posterior.Woman.Pilot[datac$condition == "2"] <- datac$cond2.post_womanPilot.manFlightAttendant[datac$condition == "2"]


## Confirm that posteriors sum to 100
count(with(datac, Posterior.Man.Pilot + Posterior.Woman.Pilot)) # doesn't work
datac$Posterior.Man.Pilot + datac$Posterior.Woman.Pilot  # -->> works #sum is 100!!

#some notes:
datac <- transform(datac, Posterior.Man.Pilot = as.numeric(Posterior.Man.Pilot), 
                          Posterior.Woman.Pilot = as.numeric(Posterior.Woman.Pilot))

## Peak at distribution of posteriors overall
hist(datac$Posterior.Man.Pilot)

## ================================================================================================= ##

## Posterior.Target.Pilot
datac$Posterior.Target.Pilot <- ifelse(test = datac$target == "man", 
                                     yes = datac$Posterior.Man.Pilot, 
                                     no = datac$Posterior.Woman.Pilot)




colnames(datac)
# exclude columns with demographic info -> for analysis
data_clean <- select(datac, ResponseId, 11:34,42:50)
colnames(data_clean)
```


### Sorting Posterior Attributions

```{r}

## ================================================================================================== ##
## Calculate model posterior; compare to reported posterior

## Create new dataframe (#maybe don't run this for now)
# prior.model.reported <- merge(x = dat[,c("ResponseID", "target",
#                                          "Prior.Man.Pilot", "Prior.Woman.Pilot", "Prior.Target.Pilot", 
#                                          "Posterior.Man.Pilot", "Posterior.Woman.Pilot", "Posterior.Target.Pilot")], 
#                               y = LR.dat[,c("ResponseID", "LR")], 
#                               by = "ResponseID",
#                               all.x = FALSE, 
#                               all.y = TRUE)

prior.model.reported <- select(data_clean,
                               ResponseId, target, Prior.Man.Pilot, Prior.Woman.Pilot, Prior.Target.Pilot,
                               Posterior.Man.Pilot, Posterior.Woman.Pilot, Posterior.Target.Pilot)
colnames(prior.model.reported)


## ================================================================================================== #

# GET odds ratio then convert to percent


## Create prior.odds.ratio: divide differently for when target is man vs. woman
prior.model.reported$prior.odds.ratio <- ifelse(test = prior.model.reported$target == "man", 
                                                yes = prior.model.reported$Prior.Man.Pilot / prior.model.reported$Prior.Woman.Pilot, 
                                                no = prior.model.reported$Prior.Woman.Pilot / prior.model.reported$Prior.Man.Pilot)

## Create posterior.odds.ratio: divide differently for when target is man vs. woman
prior.model.reported$posterior.odds.ratio <- ifelse(test = prior.model.reported$target == "man", 
                                                    yes = prior.model.reported$Posterior.Man.Pilot / prior.model.reported$Posterior.Woman.Pilot, 
                                                    no = prior.model.reported$Posterior.Woman.Pilot / prior.model.reported$Posterior.Man.Pilot)


## ignore Calculation of model.posterior.odds.ratio

## Convert the following to percent format:
## prior.odds.ratio
## posterior.odds.ratio
## model.posterior.odds.ratio

## prior.odds.ratio --> percent format
prior.model.reported$prior_percent <- with(prior.model.reported, prior.odds.ratio / (1 + prior.odds.ratio) )

tapply(X = prior.model.reported$prior_percent, 
       INDEX = prior.model.reported$target, 
       FUN = mean)

## posterior.odds.ratio --> percent format
prior.model.reported$posterior_percent <- ifelse(test = is.infinite(prior.model.reported$posterior.odds.ratio) == TRUE, 
                                                 yes = 1, 
                                                 no = ( prior.model.reported$posterior.odds.ratio / (1 + prior.model.reported$posterior.odds.ratio) )
                                                )

tapply(X = prior.model.reported$posterior_percent, 
       INDEX = list(prior.model.reported$target), 
       FUN = mean)

 # excluded model posterior odds cause we dont care about it

## ================================================================================================== ##
## Create long form version for plotting purposes
library(reshape2)
prior.model.reported_long <- melt(prior.model.reported, measure.vars = c("prior_percent", "posterior_percent"))
348*3
  ## Each subject gives three responses: prior, model posterior, and reported posterior

prior.model.reported_long$variable <- factor(prior.model.reported_long$variable, 
                                             levels = c("prior_percent", "posterior_percent"), #emovd middle argument
                                             labels = c("Prior", "Reported Posterior")) #Removed middle argument

prior.model.reported_long$target <- factor(prior.model.reported_long$target, #dont run we dont care about models
                                           levels = c("man", "woman"), 
                                           labels = c("Man", "Woman"))

prior.model.reported_long

```


### Person X attributions analyses

```{r include=F}

# create column that averages intelligent, fair, just and accurate judgments

colnames(prior.model.reported)

colnames(data_clean)

select(data_clean, c1.intel)

## Collapse responses
data_clean$intelligent <- ifelse(test = data_clean$condition == "1", 
                          yes = data_clean$c1.intel, 
                          no = data_clean$c2.intel)

data_clean$accurate <- ifelse(test = data_clean$condition == "1", 
                       yes = data_clean$c1.acc, 
                       no = data_clean$c2.acc)

data_clean$fair <- ifelse(test = data_clean$condition == "1", 
                   yes = data_clean$c1.fair, 
                   no = data_clean$c2.fair)

data_clean$just <- ifelse(test = data_clean$condition == "1", 
                   yes = data_clean$c1.just, 
                   no = data_clean$c2.just)

## Create dataset with just composite items
data.composite <- data_clean[,c("intelligent", "accurate", "fair", "just")]

data.composite <- melt(data.composite, measure.vars = c("intelligent", "accurate", "fair", "just"))


## Compute composite average
data_clean$composite.avg <- with(data_clean, (intelligent + accurate + fair + just) / 4)

colnames(data_clean)
```
### Plots

```{r}

# willl be linear ANVOVA of posterior percent vs person X attributions

data_plot <- merge(x = data_clean, 
             y = prior.model.reported[,c("ResponseId", "posterior_percent")], #removed argument "model posterior percent"
             by = "ResponseId")

library(scales)
data_plotted <- ggplot(data = data_plot,
    mapping = aes(x = composite.avg, y = posterior_percent, color = target)) + 
  geom_smooth(method = "lm", se = TRUE) + 
  labs(x = "<-Negative    Positive->\n\nEvaluation of Person X",
       y = expression(paste(italic(P), "(Target = Pilot)"))) + 
  coord_cartesian(xlim = c(0.5, 7.5),
                  ylim = c(0, 1)) + 
  scale_x_continuous(breaks = seq(1, 7, 1)) + 
  scale_y_continuous(breaks = seq(0, 1, 0.10),
                     label = percent_format()) + 
  scale_color_discrete(labels = c("Man communicated w/ATC",
                                  "Woman communicated w/ATC"))

data_plotted
```

# Analyses

```{r}

## Main effect of target
data_plot$composite.avg.shifted <- data_plot$composite.avg - 1

anova(lm(formula = posterior_percent ~ composite.avg.shifted * target, 
         data = data_plot))

```


For finding about participants making Bayesian judgments: A two-way  will be conducted to investigate whether participant's model and reported posteriors favor the man or the woman to be the pilot. This will also be used to compute the difference between the model and reported posteriors among those who learnt that the man versus the woman communicated with ATC. 

For finding about moral judgment criticizing person X:The means of all 4 scales will be averaged in each condition to form a composite measure of participant's evaluation of person X.

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
